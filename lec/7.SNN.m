%변수 설정 (4kW의 출력을 가진 모델 학습시키고자 할 때)
%x1: laser power, x2: welding speed, x3: beam diameter
x1=4;
x2=linspace(1,7,100);
x3=linspace(0.1,0.7,100);
[numRows,numCols] = size(x2);

%그래프 label 지정
Z2 = NNCal(x1,x2,x3,numCols);
axlbl = @(h) [xlabel(h, 'Welding speed (m/min)'); ylabel(h, 'Beam diameter (mm)')];
figure(1)
contour(x2,x3,Z2,'ShowText','on')
title('Contour plot for penetration depth for 4 kW laser power')
axlbl(gca);

function[Z] = NNCal(x1,x2,x3,numCols)
Z = zeros(numCols, numCols);
 for i = 1:numCols
     for j = 1:numCols
 	testx=[x1,x2(j),x3(i)];
 	Z(i,j) = myNeuralNetworkFunction(testx);
     end
 end
end

%SNN을 통해 학습된 모델 복사 붙여넣기
function [y1] = myNeuralNetworkFunction(x1)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 10-May-2021 23:34:36.
%
% [y1] = myNeuralNetworkFunction(x1) takes these arguments:
%   x = Qx3 matrix, input #1
% and returns:
%   y = Qx1 matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [0.3;0.27930174563591;0.05];
x1_step1.gain = [0.121951219512195;0.101287455393338;2.73972602739726];
x1_step1.ymin = -1;

% Layer 1
b1 = [-3.8035552271489860843;-8.4742633292209319507;-3.7075043633015338784;-0.33617447204221623247;-1.6915947660288117582;-2.1778751141218961607;1.6150011936329433659;2.7920062002254208977;-0.13066932709915940469;-4.4532470290756913656];
IW1_1 = [3.6166663014472915094 -0.47275025199469655757 2.3824166263143493616;0.42390673599917699788 -7.3741326032838800941 0.11121350847020483599;1.6915539108729258366 0.32574640499698526153 1.1728421346359618749;-2.6421106491688308715 -2.5797126636474314587 -2.4537415917893241613;-0.05640047412645626812 -2.4561890829777790479 -0.11074297109902196679;-2.1933946935309829307 -0.79231496972231596487 0.15577212620501545981;1.3473271817208054557 0.28604258893406708797 -0.09864752243301237733;3.975870394959239551 -0.5516279669509787098 -0.47087457883165823036;-0.97952864977123321744 -1.0105354034857216838 -0.53205981523052336968;-1.927138385923358177 0.8720329693181481101 2.6408039310725941462];

% Layer 2
b2 = 0.10643207186021642896;
LW2_1 = [0.58708731904861777284 3.4606811438230784539 -1.4723910243715458979 -0.11242644214388360091 0.19603603847505862712 1.1419006095270598511 4.1572789660878033402 -0.25958652183498986954 0.66738324886310640416 0.22869388665753409562];

% Output 1
y1_step1.ymin = -1;
y1_step1.gain = 0.132931762032067;
y1_step1.xoffset = 0.192691104407987;

% ===== SIMULATION ========

% Dimensions
Q = size(x1,1); % samples

% Input 1
x1 = x1';
xp1 = mapminmax_apply(x1,x1_step1);

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = repmat(b2,1,Q) + LW2_1*a1;

% Output 1
y1 = mapminmax_reverse(a2,y1_step1);
y1 = y1';
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings)
x = bsxfun(@minus,y,settings.ymin);
x = bsxfun(@rdivide,x,settings.gain);
x = bsxfun(@plus,x,settings.xoffset);
end

